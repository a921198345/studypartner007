#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•çœŸå®æ³•å¾‹æ–‡æ¡£çš„åˆ†æ®µæ•ˆæœ
"""

import os
import sys
import time
from text_segmentation import LegalDocumentSegmenter
from enhanced_legal_structure import AIEnhancedLegalProcessor

def extract_text_from_docx(file_path):
    """ä»Wordæ–‡æ¡£ä¸­æå–æ–‡æœ¬"""
    try:
        import docx
        doc = docx.Document(file_path)
        full_text = []
        for para in doc.paragraphs:
            full_text.append(para.text)
        return '\n'.join(full_text)
    except ImportError:
        print("è¯·å®‰è£…python-docxåº“: pip install python-docx")
        return None
    except Exception as e:
        print(f"æå–æ–‡æœ¬å‡ºé”™: {e}")
        return None

def test_constitution():
    """æµ‹è¯•å®ªæ³•æ–‡æ¡£çš„åˆ†æ®µæ•ˆæœ"""
    print("\n" + "="*50)
    print("ğŸ“œ æµ‹è¯•å®ªæ³•æ–‡æ¡£")
    print("="*50)
    
    # æ–‡ä»¶è·¯å¾„
    file_path = "å®ªæ³•.docx"
    if not os.path.exists(file_path):
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°å®ªæ³•æ–‡æ¡£ '{file_path}'")
        return
    
    # æå–æ–‡æœ¬
    print(f"ğŸ“‘ æ­£åœ¨ä» {file_path} æå–æ–‡æœ¬...")
    text = extract_text_from_docx(file_path)
    if not text:
        print("âŒ æ–‡æœ¬æå–å¤±è´¥")
        return
    
    print(f"âœ… æ–‡æœ¬æå–æˆåŠŸï¼Œå…± {len(text)} ä¸ªå­—ç¬¦")
    print(f"ğŸ“ å‰200ä¸ªå­—ç¬¦é¢„è§ˆ: {text[:200].replace('
', ' ')}...")
    
    # ä½¿ç”¨åŸºç¡€åˆ†æ®µå™¨
    print("\nğŸ” ä½¿ç”¨åŸºç¡€æ³•å¾‹ç»“æ„åˆ†æ®µå™¨...")
    segmenter = LegalDocumentSegmenter()
    
    start_time = time.time()
    segments = segmenter.segment_by_legal_structure(text, "ä¸­åäººæ°‘å…±å’Œå›½å®ªæ³•")
    end_time = time.time()
    
    print(f"âœ… åˆ†æ®µå®Œæˆï¼Œè€—æ—¶ {end_time - start_time:.2f} ç§’")
    print(f"ğŸ“Š å…±ç”Ÿæˆ {len(segments)} ä¸ªåˆ†æ®µ")
    
    # æ˜¾ç¤ºå‰5ä¸ªåˆ†æ®µ
    print("\nğŸ“‹ å‰5ä¸ªåˆ†æ®µé¢„è§ˆ:")
    for i, segment in enumerate(segments[:5], 1):
        print(f"\nåˆ†æ®µ #{i}:")
        print(f"ğŸ“ ä½ç½®: " + " > ".join(filter(None, [
            segment.book, 
            segment.chapter, 
            segment.section, 
            f"ç¬¬{segment.article}æ¡" if segment.article else None
        ])))
        print(f"ğŸ“ å†…å®¹: {segment.content[:100].replace('
', ' ')}...")
    
    # ç»Ÿè®¡
    print("\nğŸ“Š åˆ†æ®µç»Ÿè®¡:")
    books = set(s.book for s in segments if s.book)
    chapters = set(s.chapter for s in segments if s.chapter)
    sections = set(s.section for s in segments if s.section)
    articles = set(s.article for s in segments if s.article)
    
    print(f"ğŸ“š è¯†åˆ«åˆ°çš„ç¼–æ•°: {len(books)}")
    print(f"ğŸ“– è¯†åˆ«åˆ°çš„ç« æ•°: {len(chapters)}")
    print(f"ğŸ“‘ è¯†åˆ«åˆ°çš„èŠ‚æ•°: {len(sections)}")
    print(f"ğŸ“œ è¯†åˆ«åˆ°çš„æ¡æ•°: {len(articles)}")
    
    return segments

def test_enhanced_processing(segments=None):
    """æµ‹è¯•AIå¢å¼ºåŠŸèƒ½"""
    # æ£€æŸ¥æ˜¯å¦è®¾ç½®äº†APIå¯†é’¥
    if not os.environ.get("DEEPSEEK_API_KEY"):
        print("\nâš ï¸  è­¦å‘Š: æœªè®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡ï¼ŒAIå¢å¼ºåŠŸèƒ½å¯èƒ½ä¸å¯ç”¨")
    
    print("\n" + "="*50)
    print("ğŸ¤– æµ‹è¯•AIå¢å¼ºåŠŸèƒ½")
    print("="*50)
    
    if not segments:
        print("âŒ æ²¡æœ‰åˆ†æ®µæ•°æ®ï¼Œè·³è¿‡AIå¢å¼ºæµ‹è¯•")
        return
    
    # ä½¿ç”¨AIå¢å¼ºå¤„ç†å™¨
    processor = AIEnhancedLegalProcessor()
    
    # æµ‹è¯•ä¸€ä¸ªå°æ ·æœ¬
    test_segments = segments[:3]  # åªå–å‰3ä¸ªåˆ†æ®µè¿›è¡Œæµ‹è¯•
    
    print(f"ğŸ§ª å¯¹ {len(test_segments)} ä¸ªåˆ†æ®µè¿›è¡ŒAIå¢å¼ºæµ‹è¯•...")
    
    # æ¨¡æ‹Ÿå‘é‡åŒ–å¤„ç†
    print("âš¡ æµ‹è¯•å‘é‡åŒ–å¤„ç†...")
    embeddings = processor.generate_embeddings(test_segments)
    
    print(f"âœ… å‘é‡åŒ–å®Œæˆï¼Œç”Ÿæˆ {len(embeddings)} ä¸ªå‘é‡")
    
    if len(embeddings) > 0:
        sample = embeddings[0]
        print(f"\nğŸ“Š å‘é‡æ ·æœ¬:")
        print(f"ğŸ†” ID: {sample['segment_id']}")
        print(f"ğŸ“Š å‘é‡ç»´åº¦: {len(sample['embedding'])}")
        print(f"ğŸ”‘ å…³é”®æ¦‚å¿µ: {', '.join(sample.get('key_concepts', ['æ— å…³é”®æ¦‚å¿µ'])[:3])}...")
    
    return embeddings

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•çœŸå®æ³•å¾‹æ–‡æ¡£")
    
    # æµ‹è¯•å®ªæ³•æ–‡æ¡£
    segments = test_constitution()
    
    # æµ‹è¯•AIå¢å¼ºåŠŸèƒ½
    embeddings = test_enhanced_processing(segments)
    
    print("\nâœ¨ æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main() 