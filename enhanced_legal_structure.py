#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIå¢å¼ºçš„æ³•å¾‹æ–‡æ¡£å¤„ç†æ¨¡å—
é›†æˆDeepSeek APIï¼Œæä¾›æ™ºèƒ½ç»“æ„è¯†åˆ«å’Œåˆ†æ®µä¼˜åŒ–
"""

import re
import json
import requests
import os
from typing import List, Dict, Any, Optional
from text_segmentation import LegalDocumentSegmenter, LegalSegment

class AIEnhancedLegalProcessor:
    """AIå¢å¼ºçš„æ³•å¾‹æ–‡æ¡£å¤„ç†å™¨"""
    
    def __init__(self, api_key: str = None):
        self.base_segmenter = LegalDocumentSegmenter()
        self.api_key = api_key or os.getenv('DEEPSEEK_API_KEY')
        # æ›´æ–°åˆ°æœ€æ–°APIç«¯ç‚¹
        self.api_base_url = "https://api.deepseek.com"
        
        if not self.api_key:
            print("âš ï¸  è­¦å‘Š: æœªè®¾ç½®DEEPSEEK_API_KEYï¼ŒAIå¢å¼ºåŠŸèƒ½å°†ä¸å¯ç”¨")
    
    def call_deepseek_api(self, prompt: str, model: str = "deepseek-chat") -> str:
        """è°ƒç”¨DeepSeek API"""
        if not self.api_key:
            raise ValueError("éœ€è¦è®¾ç½®DEEPSEEK_API_KEYæ‰èƒ½ä½¿ç”¨AIåŠŸèƒ½")
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": model,
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.1,  # è¾ƒä½æ¸©åº¦ç¡®ä¿ç»“æœä¸€è‡´æ€§
            "max_tokens": 1000
        }
        
        try:
            response = requests.post(
                f"{self.api_base_url}/v1/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )
            response.raise_for_status()
            
            result = response.json()
            return result["choices"][0]["message"]["content"]
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}")
            return ""
    
    def ai_enhance_structure_recognition(self, text: str) -> Dict[str, Any]:
        """ä½¿ç”¨AIå¢å¼ºæ³•å¾‹æ–‡æ¡£ç»“æ„è¯†åˆ«"""
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹æ³•å¾‹æ–‡æ¡£çš„ç»“æ„ï¼Œè¯†åˆ«å…¶å±‚æ¬¡å…³ç³»ï¼š

æ–‡æ¡£å†…å®¹ï¼š
{text[:2000]}  # åªå–å‰2000å­—ç¬¦é¿å…tokenè¿‡å¤š

è¯·è¿”å›JSONæ ¼å¼çš„ç»“æ„åˆ†æï¼ŒåŒ…æ‹¬ï¼š
1. æ–‡æ¡£ç±»å‹ï¼ˆæ³•å¾‹ã€æ³•è§„ã€æ¡ä¾‹ç­‰ï¼‰
2. ä¸»è¦ç»“æ„å±‚æ¬¡ï¼ˆç¼–ã€ç« ã€èŠ‚ã€æ¡ç­‰ï¼‰
3. å»ºè®®çš„åˆ†æ®µç­–ç•¥
4. ç‰¹æ®Šæ ¼å¼è¯´æ˜

è¿”å›æ ¼å¼ï¼š
{{
    "document_type": "æ³•å¾‹æ–‡æ¡£ç±»å‹",
    "structure_levels": ["ç¼–", "ç« ", "èŠ‚", "æ¡"],
    "segmentation_strategy": "å»ºè®®çš„åˆ†æ®µæ–¹å¼",
    "special_formats": ["ç‰¹æ®Šæ ¼å¼è¯´æ˜"]
}}
"""
        
        try:
            ai_response = self.call_deepseek_api(prompt)
            # å°è¯•è§£æJSONå“åº”
            if ai_response:
                # æå–JSONéƒ¨åˆ†
                json_match = re.search(r'\{.*\}', ai_response, re.DOTALL)
                if json_match:
                    return json.loads(json_match.group())
        except Exception as e:
            print(f"âš ï¸  AIç»“æ„åˆ†æå¤±è´¥: {e}")
        
        # è¿”å›é»˜è®¤ç»“æ„
        return {
            "document_type": "æ³•å¾‹æ–‡æ¡£",
            "structure_levels": ["ç¼–", "ç« ", "èŠ‚", "æ¡"],
            "segmentation_strategy": "æŒ‰æ¡æ–‡åˆ†æ®µ",
            "special_formats": []
        }
    
    def check_segment_quality(self, segment: LegalSegment) -> Dict[str, Any]:
        """
        æ£€æŸ¥åˆ†æ®µè´¨é‡
        
        Args:
            segment: éœ€è¦æ£€æŸ¥çš„åˆ†æ®µ
            
        Returns:
            åŒ…å«è´¨é‡è¯„ä¼°ç»“æœçš„å­—å…¸
        """
        # åˆå§‹åŒ–è¯„ä¼°ç»“æœ
        quality_assessment = {
            "is_complete": True,
            "issues": [],
            "score": 10  # 1-10åˆ†æ•°
        }
        
        # 1. æ£€æŸ¥å†…å®¹é•¿åº¦ (å¤ªçŸ­å¯èƒ½ä¸æ˜¯å®Œæ•´è¯­ä¹‰å•å…ƒ)
        content_length = len(segment.content)
        if content_length < 50:
            quality_assessment["is_complete"] = False
            quality_assessment["issues"].append("å†…å®¹è¿‡çŸ­ï¼Œå¯èƒ½ä¸æ˜¯å®Œæ•´è¯­ä¹‰å•å…ƒ")
            quality_assessment["score"] -= 2
        
        # 2. æ£€æŸ¥å…ƒæ•°æ®å®Œæ•´æ€§
        if not segment.article and not segment.chapter:
            quality_assessment["issues"].append("ç¼ºå°‘å…³é”®ç»“æ„ä¿¡æ¯(æ¡/ç« )")
            quality_assessment["score"] -= 2
            
        # 3. æ£€æŸ¥å†…å®¹æ˜¯å¦æœ‰æ˜ç¡®çš„å¼€å§‹å’Œç»“æŸ
        content = segment.content.strip()
        if not content.endswith(("ã€‚", "ï¼", "ï¼Ÿ", "ï¼›", ".", "!", "?", ";")):
            quality_assessment["issues"].append("å†…å®¹å¯èƒ½ä¸å®Œæ•´ï¼Œç¼ºå°‘é€‚å½“çš„ç»“æŸç¬¦")
            quality_assessment["score"] -= 1
            
        # 4. æ£€æŸ¥è¯­ä¹‰è¿è´¯æ€§ (é€šè¿‡AIå®Œæˆ)
        if self.api_key and len(content) > 100:  # åªå¯¹è¾ƒé•¿æ–‡æœ¬è°ƒç”¨AI
            ai_assessment = self._assess_semantic_quality(segment)
            if ai_assessment:
                if not ai_assessment.get("is_coherent", True):
                    quality_assessment["issues"].append("AIæ£€æµ‹åˆ°è¯­ä¹‰ä¸è¿è´¯é—®é¢˜")
                    quality_assessment["score"] -= 2
                
                # åˆå¹¶AIè¯„ä¼°ç»“æœ
                quality_assessment.update({
                    "ai_assessment": ai_assessment
                })
        
        # ç¡®ä¿æœ€ç»ˆåˆ†æ•°åœ¨1-10èŒƒå›´å†…
        quality_assessment["score"] = max(1, min(10, quality_assessment["score"]))
        
        return quality_assessment
    
    def _assess_semantic_quality(self, segment: LegalSegment) -> Dict[str, Any]:
        """ä½¿ç”¨AIè¯„ä¼°åˆ†æ®µçš„è¯­ä¹‰è´¨é‡"""
        if not self.api_key:
            return {}
            
        prompt = f"""
åˆ†æä»¥ä¸‹æ³•å¾‹æ¡æ–‡åˆ†æ®µçš„è¯­ä¹‰è´¨é‡:

åˆ†æ®µå†…å®¹:
{segment.content}

å…ƒæ•°æ®:
æ³•å¾‹: {segment.law_name}
ç« : {segment.chapter or 'æ— '}
æ¡: {segment.article or 'æ— '}

è¯·è¯„ä¼°:
1. å†…å®¹æ˜¯å¦è¯­ä¹‰è¿è´¯ï¼Ÿ
2. æ˜¯å¦åŒ…å«å®Œæ•´çš„æ³•å¾‹è¡¨è¿°ï¼Ÿ
3. æœ‰æ— è¯­ä¹‰æ–­è£‚æˆ–ä¸è¿è´¯ä¹‹å¤„ï¼Ÿ

ä»¥JSONæ ¼å¼å›ç­”:
{{
  "is_coherent": true/false,
  "is_complete_statement": true/false,
  "issues": ["é—®é¢˜1", "é—®é¢˜2"...],
  "improvement": "æ”¹è¿›å»ºè®®"
}}
"""
        
        try:
            response = self.call_deepseek_api(prompt)
            # å°è¯•æå–JSON
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
        except Exception as e:
            print(f"âš ï¸ AIè¯­ä¹‰è¯„ä¼°å¤±è´¥: {e}")
        
        return {}
    
    def ai_optimize_segmentation(self, segments: List[LegalSegment]) -> List[LegalSegment]:
        """ä½¿ç”¨AIä¼˜åŒ–åˆ†æ®µè´¨é‡"""
        if not self.api_key:
            print("âš ï¸  è·³è¿‡AIä¼˜åŒ–ï¼ˆéœ€è¦APIå¯†é’¥ï¼‰")
            return segments
        
        print(f"ğŸ” æ­£åœ¨è¯„ä¼°å¹¶ä¼˜åŒ– {len(segments)} ä¸ªåˆ†æ®µçš„è´¨é‡...")
        optimized_segments = []
        quality_scores = []
        
        # å…ˆè¿›è¡Œè´¨é‡æ£€æŸ¥ï¼Œæ‰¾å‡ºéœ€è¦ä¼˜åŒ–çš„åˆ†æ®µ
        for i, segment in enumerate(segments):
            print(f"  è¯„ä¼°åˆ†æ®µ {i+1}/{len(segments)}...")
            quality = self.check_segment_quality(segment)
            quality_scores.append(quality)
            
            # å¦‚æœè´¨é‡åˆ†æ•°ä½äºé˜ˆå€¼ï¼Œè¿›è¡Œä¼˜åŒ–
            if quality["score"] < 7:
                optimized_segment = self._optimize_single_segment(segment, quality)
                optimized_segments.append(optimized_segment)
                print(f"  âœ¨ åˆ†æ®µ {i+1} å·²ä¼˜åŒ–ï¼ŒåŸå§‹åˆ†æ•°: {quality['score']}")
            else:
                optimized_segments.append(segment)
                print(f"  âœ… åˆ†æ®µ {i+1} è´¨é‡è‰¯å¥½ï¼Œåˆ†æ•°: {quality['score']}")
        
        # è¾“å‡ºè´¨é‡ç»Ÿè®¡
        scores = [q["score"] for q in quality_scores]
        if scores:
            avg_score = sum(scores) / len(scores)
            print(f"ğŸ“Š åˆ†æ®µè´¨é‡ç»Ÿè®¡ï¼šå¹³å‡åˆ†æ•° {avg_score:.1f}ï¼Œæœ€ä½ {min(scores)}ï¼Œæœ€é«˜ {max(scores)}")
            
        return optimized_segments
    
    def _optimize_single_segment(self, segment: LegalSegment, quality: Dict[str, Any]) -> LegalSegment:
        """ä¼˜åŒ–å•ä¸ªåˆ†æ®µ"""
        if not self.api_key:
            return segment
            
        issues = quality.get("issues", [])
        issues_str = "\n".join([f"- {issue}" for issue in issues])
            
        prompt = f"""
ä½œä¸ºæ³•å¾‹æ–‡æœ¬åˆ†æ®µä¼˜åŒ–ä¸“å®¶ï¼Œè¯·ä¼˜åŒ–ä»¥ä¸‹æ³•å¾‹åˆ†æ®µå†…å®¹ï¼Œè§£å†³å­˜åœ¨çš„è´¨é‡é—®é¢˜:

åŸå§‹åˆ†æ®µå†…å®¹:
{segment.content}

å…ƒæ•°æ®:
- æ³•å¾‹: {segment.law_name}
- ç¼–: {segment.book or 'æ— '}
- ç« : {segment.chapter or 'æ— '}
- èŠ‚: {segment.section or 'æ— '}
- æ¡: {segment.article or 'æ— '}

æ£€æµ‹åˆ°çš„é—®é¢˜:
{issues_str}

è¯·æ‰§è¡Œä»¥ä¸‹ä¼˜åŒ–:
1. ä¿®æ­£ä¸è¿è´¯æˆ–ä¸å®Œæ•´çš„è¡¨è¿°
2. ç¡®ä¿è¯­ä¹‰å®Œæ•´æ€§
3. ä¿ç•™åŸå§‹æ³•å¾‹å«ä¹‰å’Œä¸“ä¸šæœ¯è¯­
4. ä¿æŒåŸæ–‡ç»“æ„å’Œæ ¼å¼
5. ä¸è¦æ·»åŠ åŸæ–‡ä¸­ä¸å­˜åœ¨çš„æ³•å¾‹è§£é‡Š

åªè¿”å›ä¼˜åŒ–åçš„æ–‡æœ¬å†…å®¹ï¼Œä¸è¦æ·»åŠ è§£é‡Šæˆ–å…¶ä»–å†…å®¹ã€‚
"""
        
        try:
            response = self.call_deepseek_api(prompt)
            if response:
                # å¤åˆ¶åŸåˆ†æ®µï¼Œä½†æ›¿æ¢å†…å®¹ä¸ºä¼˜åŒ–åçš„å†…å®¹
                return LegalSegment(
                    content=response,
                    law_name=segment.law_name,
                    book=segment.book,
                    chapter=segment.chapter,
                    section=segment.section,
                    article=segment.article,
                    paragraph=segment.paragraph,
                    item=segment.item,
                    token_count=self.base_segmenter.estimate_tokens(response)
                )
        except Exception as e:
            print(f"âš ï¸ åˆ†æ®µä¼˜åŒ–å¤±è´¥: {e}")
        
        # å¦‚æœä¼˜åŒ–å¤±è´¥ï¼Œè¿”å›åŸå§‹åˆ†æ®µ
        return segment
    
    def extract_key_concepts(self, segment: LegalSegment) -> List[str]:
        """æå–åˆ†æ®µä¸­çš„å…³é”®æ³•å¾‹æ¦‚å¿µ"""
        if not self.api_key:
            return []
        
        prompt = f"""
è¯·ä»ä»¥ä¸‹æ³•å¾‹æ¡æ–‡ä¸­æå–å…³é”®çš„æ³•å¾‹æ¦‚å¿µå’Œæœ¯è¯­ï¼š

æ¡æ–‡å†…å®¹ï¼š
{segment.content}

è¯·è¿”å›JSONæ ¼å¼çš„å…³é”®æ¦‚å¿µåˆ—è¡¨ï¼š
{{"concepts": ["æ¦‚å¿µ1", "æ¦‚å¿µ2", "æ¦‚å¿µ3"]}}
"""
        
        try:
            ai_response = self.call_deepseek_api(prompt)
            json_match = re.search(r'\{.*\}', ai_response, re.DOTALL)
            
            if json_match:
                result = json.loads(json_match.group())
                return result.get("concepts", [])
                
        except Exception as e:
            print(f"âš ï¸  æ¦‚å¿µæå–å¤±è´¥: {e}")
        
        return []
    
    def generate_embeddings_for_text(self, text: str, model: str = "text-embedding-ada-002") -> List[float]:
        """
        ä¸ºæ–‡æœ¬ç”Ÿæˆå‘é‡åµŒå…¥
        
        Args:
            text: éœ€è¦å‘é‡åŒ–çš„æ–‡æœ¬
            model: ä½¿ç”¨çš„åµŒå…¥æ¨¡å‹åç§°
            
        Returns:
            å‘é‡åˆ—è¡¨
        """
        if not self.api_key:
            # è¿”å›è™šæ‹Ÿå‘é‡ï¼ˆå®é™…é¡¹ç›®ä¸­è¿™é‡Œä¸åº”è¯¥è¿™æ ·å¤„ç†ï¼‰
            return [0.1] * 512
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": model,
            "input": text,
            "encoding_format": "float"
        }
        
        try:
            response = requests.post(
                f"{self.api_base_url}/v1/embeddings",
                headers=headers,
                json=data,
                timeout=30
            )
            response.raise_for_status()
            
            result = response.json()
            return result["data"][0]["embedding"]
            
        except requests.exceptions.RequestException as e:
            print(f"âŒ åµŒå…¥ç”Ÿæˆå¤±è´¥: {str(e)}")
            # è¿”å›è™šæ‹Ÿå‘é‡
            return [0.1] * 512
    
    def generate_embeddings(self, segments: List[LegalSegment]) -> List[Dict[str, Any]]:
        """ä¸ºåˆ†æ®µç”Ÿæˆå‘é‡åµŒå…¥"""
        results = []
        
        print(f"â³ æ­£åœ¨ä¸º {len(segments)} ä¸ªåˆ†æ®µç”Ÿæˆå‘é‡åµŒå…¥...")
        
        for i, segment in enumerate(segments):
            print(f"  å¤„ç†åˆ†æ®µ {i+1}/{len(segments)}...")
            
            # æå–å…³é”®æ¦‚å¿µ
            key_concepts = self.extract_key_concepts(segment)
            
            # ç”Ÿæˆæ–‡æœ¬çš„å‘é‡åµŒå…¥
            embedding = self.generate_embeddings_for_text(segment.content)
            
            result = {
                "segment_id": f"{segment.law_name}_{segment.article or i}",
                "content": segment.content,
                "metadata": segment.to_dict()["metadata"],
                "key_concepts": key_concepts,
                "embedding": embedding,
                "embedding_model": "text-embedding-ada-002",
                "token_count": segment.token_count
            }
            
            results.append(result)
        
        print(f"âœ… å‘é‡åµŒå…¥ç”Ÿæˆå®Œæˆ")
        return results
    
    def process_legal_document(
        self, 
        text: str, 
        law_name: str,
        use_ai_enhancement: bool = True
    ) -> Dict[str, Any]:
        """å®Œæ•´çš„æ³•å¾‹æ–‡æ¡£å¤„ç†æµç¨‹"""
        
        print(f"ğŸš€ å¼€å§‹å¤„ç†æ³•å¾‹æ–‡æ¡£: {law_name}")
        
        # 1. AIç»“æ„åˆ†æï¼ˆå¯é€‰ï¼‰
        structure_analysis = None
        if use_ai_enhancement and self.api_key:
            print("ğŸ¤– æ­£åœ¨è¿›è¡ŒAIç»“æ„åˆ†æ...")
            structure_analysis = self.ai_enhance_structure_recognition(text)
            print(f"âœ… ç»“æ„åˆ†æå®Œæˆ: {structure_analysis['document_type']}")
        
        # 2. åŸºç¡€åˆ†æ®µ
        print("ğŸ“ æ­£åœ¨è¿›è¡ŒåŸºç¡€åˆ†æ®µ...")
        segments = self.base_segmenter.segment_by_legal_structure(text, law_name)
        print(f"âœ… åŸºç¡€åˆ†æ®µå®Œæˆï¼Œå…± {len(segments)} ä¸ªåˆ†æ®µ")
        
        # 3. AIä¼˜åŒ–åˆ†æ®µï¼ˆå¯é€‰ï¼‰
        if use_ai_enhancement and self.api_key:
            print("ğŸ”§ æ­£åœ¨è¿›è¡ŒAIåˆ†æ®µä¼˜åŒ–...")
            segments = self.ai_optimize_segmentation(segments)
            print("âœ… åˆ†æ®µä¼˜åŒ–å®Œæˆ")
        
        # 4. ç”Ÿæˆå‘é‡åµŒå…¥
        print("âš¡ æ­£åœ¨ç”Ÿæˆå‘é‡åµŒå…¥...")
        embeddings = self.generate_embeddings(segments)
        print(f"âœ… å‘é‡ç”Ÿæˆå®Œæˆï¼Œå…± {len(embeddings)} ä¸ªå‘é‡")
        
        # 5. è¿”å›å®Œæ•´ç»“æœ
        result = {
            "law_name": law_name,
            "structure_analysis": structure_analysis,
            "segments": [segment.to_dict() for segment in segments],
            "embeddings": embeddings,
            "statistics": {
                "total_segments": len(segments),
                "total_tokens": sum(segment.token_count for segment in segments),
                "avg_tokens_per_segment": sum(segment.token_count for segment in segments) / len(segments) if segments else 0
            }
        }
        
        print("ğŸ‰ æ–‡æ¡£å¤„ç†å®Œæˆï¼")
        return result

def main():
    """æ¼”ç¤ºAIå¢å¼ºåŠŸèƒ½"""
    print("ğŸ¤– AIå¢å¼ºæ³•å¾‹æ–‡æ¡£å¤„ç†æ¼”ç¤º")
    print("=" * 60)
    
    # ç¤ºä¾‹æ–‡æ¡£
    sample_text = """
ä¸­åäººæ°‘å…±å’Œå›½åˆåŒæ³•

ç¬¬ä¸€ç«  ä¸€èˆ¬è§„å®š

ç¬¬ä¸€æ¡ ä¸ºäº†ä¿æŠ¤åˆåŒå½“äº‹äººçš„åˆæ³•æƒç›Šï¼Œç»´æŠ¤ç¤¾ä¼šç»æµç§©åºï¼Œä¿ƒè¿›ç¤¾ä¼šä¸»ä¹‰ç°ä»£åŒ–å»ºè®¾ï¼Œåˆ¶å®šæœ¬æ³•ã€‚

ç¬¬äºŒæ¡ æœ¬æ³•æ‰€ç§°åˆåŒæ˜¯å¹³ç­‰ä¸»ä½“çš„è‡ªç„¶äººã€æ³•äººã€å…¶ä»–ç»„ç»‡ä¹‹é—´è®¾ç«‹ã€å˜æ›´ã€ç»ˆæ­¢æ°‘äº‹æƒåˆ©ä¹‰åŠ¡å…³ç³»çš„åè®®ã€‚
å©šå§»ã€æ”¶å…»ã€ç›‘æŠ¤ç­‰æœ‰å…³èº«ä»½å…³ç³»çš„åè®®ï¼Œé€‚ç”¨å…¶ä»–æ³•å¾‹çš„è§„å®šã€‚

ç¬¬ä¸‰æ¡ åˆåŒå½“äº‹äººçš„æ³•å¾‹åœ°ä½å¹³ç­‰ï¼Œä¸€æ–¹ä¸å¾—å°†è‡ªå·±çš„æ„å¿—å¼ºåŠ ç»™å¦ä¸€æ–¹ã€‚

ç¬¬å››æ¡ å½“äº‹äººä¾æ³•äº«æœ‰è‡ªæ„¿è®¢ç«‹åˆåŒçš„æƒåˆ©ï¼Œä»»ä½•å•ä½å’Œä¸ªäººä¸å¾—éæ³•å¹²é¢„ã€‚
"""
    
    # åˆ›å»ºAIå¢å¼ºå¤„ç†å™¨ï¼ˆæ³¨æ„ï¼šéœ€è¦è®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡ï¼‰
    processor = AIEnhancedLegalProcessor()
    
    # å¤„ç†æ–‡æ¡£
    result = processor.process_legal_document(
        sample_text, 
        "ä¸­åäººæ°‘å…±å’Œå›½åˆåŒæ³•",
        use_ai_enhancement=False  # è®¾ä¸ºFalseé¿å…APIè°ƒç”¨
    )
    
    # æ˜¾ç¤ºç»“æœ
    print("\nğŸ“Š å¤„ç†ç»“æœç»Ÿè®¡:")
    stats = result["statistics"]
    print(f"ğŸ“‹ æ€»åˆ†æ®µæ•°: {stats['total_segments']}")
    print(f"âš¡ æ€»Tokenæ•°: {stats['total_tokens']}")
    print(f"ğŸ“Š å¹³å‡Tokenæ•°: {stats['avg_tokens_per_segment']:.1f}")
    
    print("\nğŸ“ åˆ†æ®µé¢„è§ˆ:")
    for i, segment_data in enumerate(result["segments"][:3], 1):
        metadata = segment_data["metadata"]
        content_preview = segment_data["content"][:100] + "..."
        print(f"\n{i}. ğŸ“ {metadata['law_name']} > {metadata['chapter']} > ç¬¬{metadata['article']}æ¡")
        print(f"   ğŸ’¬ {content_preview}")

if __name__ == "__main__":
    main() 