# 法律文档智能处理系统文档

## 1. 系统概述

法律文档智能处理系统是一个专为法律考试辅助系统设计的功能模块，主要用于处理法律文档（如宪法、民法典等）的智能分段、向量化和结构化存储。系统能够识别法律文档中的编、章、节、条等结构元素，并根据这些结构进行智能分段，提取相关元数据，生成向量嵌入，从而为后续的检索、问答和学习提供基础支持。

### 1.1 核心功能

- **文档结构识别**：自动识别法律文档中的编、章、节、条等结构层级
- **智能分段处理**：根据法律文档结构进行智能分段，确保每个分段是完整的语义单元
- **元数据提取**：为每个分段提取关键元数据，如所属法律名称、编号、章节等
- **AI增强优化**：可选择使用DeepSeek API进行分段质量优化和关键概念提取
- **向量嵌入生成**：为分段内容生成向量嵌入，支持语义搜索功能
- **向量数据库存储**：将文本块及其向量嵌入存储到MySQL或SQLite数据库中
- **语义相似度检索**：基于向量相似度进行文档检索，支持过滤条件
- **Web界面集成**：提供友好的Web界面，支持文档上传、文本提取、文本分段、向量化和检索功能

## 2. 系统架构

系统采用模块化设计，主要包含以下核心组件：

1. **基础分段模块**（`text_segmentation.py`）
   - 实现法律文档的基础结构识别和分段功能
   - 提供多种分段策略（固定长度、段落、组合、智能混合、法律结构）

2. **AI增强模块**（`enhanced_legal_structure.py`）
   - 集成DeepSeek API，提供AI增强的结构识别和分段优化
   - 实现向量嵌入生成和关键概念提取功能

3. **文档处理模块**（`process_document.py`）
   - 提供完整的文档处理流程，从文本提取到分段存储
   - 支持批处理和状态跟踪功能

4. **向量存储模块**（`vector_store.py`）
   - 负责将文本内容转换为向量嵌入
   - 管理向量数据库的存储和检索功能
   - 支持MySQL或SQLite数据库
   - 提供高效的向量相似度搜索功能

5. **API服务**（`admin_api.py`）
   - 提供RESTful API接口，支持文档上传、文本提取、分段处理、向量化和检索
   - 处理客户端请求并返回结构化结果

6. **Web界面**
   - `upload_test.html`：文档上传和分段测试页面
   - `test_legal_segmentation.html`：法律文档分段测试页面
   - `test_vector_search.html`：向量化和检索测试页面

## 3. 安装和配置

### 3.1 基础环境设置

系统运行需要Python 3.7+环境，并依赖以下主要库：
- Flask（Web服务器）
- python-docx（Word文档处理）
- requests（API请求）
- numpy（向量计算）
- mysql-connector-python（MySQL数据库连接，可选）
- faiss-cpu（高效向量检索，可选）

### 3.2 快速安装

提供了一键安装脚本`setup_vector_db.sh`，可以通过以下命令安装所有依赖：

```bash
chmod +x setup_vector_db.sh
./setup_vector_db.sh
```

脚本会自动执行以下操作：
1. 创建并激活Python虚拟环境
2. 安装所有必要的依赖库
3. 创建必要的目录结构
4. 初始化SQLite备用数据库（如果无法使用MySQL）

### 3.3 DeepSeek API配置

要使用向量嵌入和AI增强功能，需要配置DeepSeek API密钥：

```bash
export DEEPSEEK_API_KEY=你的API密钥
```

### 3.4 数据库配置

系统支持两种数据库配置：

1. **MySQL数据库**（推荐用于生产环境）
   - 通过宝塔面板创建MySQL数据库
   - 在`admin_api.py`和`vector_store.py`中更新MySQL连接配置

2. **SQLite数据库**（推荐用于开发和测试）
   - 默认存储在`data/vector_store.db`
   - 无需额外配置，系统会自动创建

## 4. 使用说明

### 4.1 启动API服务

```bash
source venv_flask_api/bin/activate
python admin_api.py
```

服务默认在5003端口启动，可通过`http://localhost:5003/`访问。

### 4.2 文档上传和分段

1. 打开`upload_test.html`页面
2. 选择"文档上传"选项卡
3. 上传Word格式的法律文档
4. 记录返回的文档ID
5. 选择"文本分段"选项卡
6. 选择"法律结构"分段策略，输入文档ID
7. 点击"提交"按钮进行分段处理

### 4.3 文档向量化

有两种方式可以进行文档向量化：

1. **通过Web界面**
   - 打开`test_vector_search.html`页面
   - 输入文档ID和分段大小
   - 点击"执行向量化处理"按钮

2. **通过API直接调用**
   ```bash
   curl -X POST http://localhost:5003/admin/api/vectorize \
       -H "Content-Type: application/json" \
       -d '{"doc_id": "YOUR_DOC_ID", "chunk_size": 800}'
   ```

### 4.4 向量检索

1. **通过Web界面**
   - 打开`test_vector_search.html`页面
   - 输入搜索查询文本和过滤条件
   - 点击"执行检索"按钮

2. **通过API直接调用**
   ```bash
   curl -X POST http://localhost:5003/api/search \
       -H "Content-Type: application/json" \
       -d '{
           "query": "你的搜索问题",
           "top_k": 5,
           "filters": {"law_name": "中华人民共和国宪法"}
       }'
   ```

## 5. 核心API接口

### 5.1 文档上传接口

```
POST /admin/api/upload
```

接收Word文档文件上传，返回文档ID。

### 5.2 文本提取接口

```
POST /admin/api/extract
```

从已上传的文档中提取文本内容。

### 5.3 文本分段接口

```
POST /admin/api/segment
```

对文本内容进行分段处理，支持多种分段策略。

### 5.4 法律结构分段接口

```
POST /admin/api/segment_legal
```

对文本内容进行法律结构分段处理。

### 5.5 文档向量化接口

```
POST /admin/api/vectorize
```

对文档进行向量化处理并存储到向量数据库中。

### 5.6 向量检索接口

```
POST /api/search
```

基于向量相似度搜索文档内容。

## 6. 数据库结构

### 6.1 向量存储表（vector_chunks）

| 字段名 | 类型 | 描述 |
| ----- | ---- | ---- |
| id | INT/INTEGER | 自增主键 |
| doc_id | VARCHAR/TEXT | 文档ID |
| chunk_index | INT/INTEGER | 分段在文档中的索引 |
| original_text | TEXT | 分段原文 |
| vector_embedding | LONGBLOB/BLOB | 向量嵌入二进制数据 |
| source_document_name | VARCHAR/TEXT | 源文档名称 |
| chunk_id_in_document | VARCHAR/TEXT | 分段在文档中的唯一标识 |
| law_name | VARCHAR/TEXT | 法律名称 |
| book | VARCHAR/TEXT | 编 |
| chapter | VARCHAR/TEXT | 章 |
| section | VARCHAR/TEXT | 节 |
| article | VARCHAR/TEXT | 条 |
| token_count | INT/INTEGER | 分段的token数量 |
| created_at | TIMESTAMP | 创建时间 |

## 7. 开发与扩展

### 7.1 添加新的分段策略

可以在`text_segmentation.py`文件中定义新的分段函数，并在`admin_api.py`的`segment_text_api`函数中添加对应的策略处理。

### 7.2 集成其他向量数据库

可以修改`vector_store.py`文件，添加对其他向量数据库的支持，如Milvus、Qdrant等。

### 7.3 优化向量检索性能

可以通过以下方式优化检索性能：
1. 安装FAISS库实现高效向量检索
2. 添加向量索引
3. 优化数据库查询

## 8. 常见问题和解决方案

### 8.1 无法连接到MySQL数据库

原因：MySQL配置错误或未安装MySQL连接器

解决方案：
1. 检查MySQL配置参数
2. 安装mysql-connector-python：`pip install mysql-connector-python`
3. 系统会自动降级到SQLite数据库

### 8.2 DeepSeek API调用失败

原因：API密钥未配置或无效

解决方案：
1. 确认已正确设置环境变量：`export DEEPSEEK_API_KEY=你的API密钥`
2. 检查API密钥是否有效
3. 检查API请求限制和配额

### 8.3 向量检索结果不准确

原因：向量维度不匹配或数据量不足

解决方案：
1. 确保所有向量使用相同的模型和维度
2. 增加文档数量和多样性
3. 调整搜索参数和过滤条件

## 9. 未来展望

系统后续可能的发展方向：

1. **多语言支持**：扩展对多语言法律文档的处理能力
2. **深度学习模型**：引入专门针对法律文档的深度学习模型
3. **智能问答**：基于分段结果构建法律智能问答系统
4. **知识图谱**：构建法律知识图谱，实现更复杂的关联分析
5. **跨文档关联**：实现不同法律文档之间的概念和条文关联

## 10. 附录

### 10.1 依赖库

- Flask: Web服务框架
- Flask-CORS: 跨域资源共享支持
- python-docx: Word文档处理
- requests: HTTP请求库
- numpy: 向量计算库
- mysql-connector-python: MySQL数据库连接器
- faiss-cpu: 高效向量检索库

### 10.2 配置项

- `DEEPSEEK_API_KEY`: DeepSeek API密钥，用于AI增强功能
- `DATABASE_TYPE`: 数据库类型，可选"mysql"或"sqlite"
- `MYSQL_CONFIG`: MySQL数据库配置
- `SQLITE_DB_PATH`: SQLite数据库路径 