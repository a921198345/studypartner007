from flask import Flask, request, jsonify, render_template_string # 增加了 render_template_string
import os # 导入os模块，用于文件操作
import inspect # 导入 inspect 模块用于获取函数信息
import json # 用于处理JSON数据
import traceback # 用于详细错误追踪
import sqlite3 # 用于SQLite数据库
import datetime # 用于处理日期时间
from werkzeug.utils import secure_filename
import uuid
from flask_cors import CORS  # 导入CORS模块
import re
from flask import send_from_directory  # 导入send_from_directory用于提供静态文件
import threading  # 导入threading模块用于处理多线程
import time  # 导入time模块用于处理时间

# 进度跟踪字典，用于存储每个文档处理的进度信息
# 格式: {doc_id: {"status": "processing/completed/failed", "progress": 0-100, "message": "处理消息"}}
processing_status = {}

# 尝试导入MySQL连接器，如果不可用则跳过
try:
    import mysql.connector
    from mysql.connector import Error as MySQLError
    MYSQL_AVAILABLE = True
except ImportError:
    MYSQL_AVAILABLE = False
    MySQLError = Exception  # 定义一个占位符

# 导入文本提取函数
try:
    from parse_docx import extract_text_from_word
    DOCX_PARSER_AVAILABLE = True
    print("成功导入 extract_text_from_word 函数")
except ImportError as e:
    DOCX_PARSER_AVAILABLE = False
    print(f"无法导入 extract_text_from_word 函数: {str(e)}")
    # 创建一个简单的占位函数，在无法导入时使用
    def extract_text_from_word(file_path):
        raise Exception("文本提取模块未正确加载，无法处理Word文档")

# 导入文本分段函数
try:
    from text_segmentation import segment_text, segment_text_combined, segment_text_smart, segment_text_legal_structure
    TEXT_SEGMENTATION_AVAILABLE = True
    print("成功导入文本分段函数")
except ImportError as e:
    TEXT_SEGMENTATION_AVAILABLE = False
    print(f"无法导入文本分段函数: {str(e)}")
    # 创建一个简单的占位函数，在无法导入时使用
    def segment_text(full_text, strategy='fixed_length', chunk_size=500, overlap=50):
        raise Exception("文本分段模块未正确加载，无法处理文本分段")
    def segment_text_combined(full_text, max_chunk_size=1000, overlap=100):
        raise Exception("文本分段模块未正确加载，无法处理文本分段")
    def segment_text_smart(full_text, max_chunk_size=1000, overlap=100):
        raise Exception("文本分段模块未正确加载，无法处理文本分段")
    def segment_text_legal_structure(full_text, chunk_size=800):
        raise Exception("法律结构分段模块未正确加载，无法处理文本分段")

# 尝试导入增强法律结构处理模块
try:
    from enhanced_legal_structure import AIEnhancedLegalProcessor
    from process_document import process_document
    ENHANCED_LEGAL_AVAILABLE = True
    print("成功导入增强法律结构处理模块")
except ImportError as e:
    ENHANCED_LEGAL_AVAILABLE = False
    print(f"无法导入增强法律结构处理模块: {str(e)}")
    
# 导入向量存储模块
try:
    from vector_store import VectorStore
    VECTOR_STORE_AVAILABLE = True
    print("成功导入向量存储模块")
except ImportError as e:
    VECTOR_STORE_AVAILABLE = False
    print(f"无法导入向量存储模块: {str(e)}")

# =================================================================
# ======================== 数据库配置区域 ==========================
# =================================================================
# 数据库类型：可以是 "mysql" 或 "sqlite"
# 如果MySQL连接失败，将自动切换到SQLite
DATABASE_TYPE = "mysql"  # 强制使用MySQL连接到宝塔面板

# MySQL配置
MYSQL_CONFIG = {
    'host': '8.141.4.192',        # 宝塔面板服务器的IP地址或域名
    'port': 3306,                    # MySQL端口，宝塔面板默认是3306
    'user': 'law_app_user',          # 宝塔面板中的应用程序用户
    'password': 'Accd0726351x.',            # law_app_user的密码
    'database': 'law_exam_assistant' # 宝塔面板中的数据库名称
}

# SQLite配置
SQLITE_DB_PATH = os.path.join("data", "law_exam_assistant.db")
# =================================================================

# --- 导入 parse_opml_to_json_tree ---
imported_parse_function_info = "未定义 (导入前)"
parse_opml_function_to_use = None

try:
    from parse_opml import parse_opml_to_json_tree
    parse_opml_function_to_use = parse_opml_to_json_tree
    imported_parse_function_info = f"成功从 parse_opml 模块导入: {inspect.getmodule(parse_opml_to_json_tree).__name__}.{parse_opml_to_json_tree.__name__}"
except ImportError as e:
    # 找不到模块或函数
    imported_parse_function_info = f"导入错误: {str(e)}"

app = Flask(__name__) # 创建一个Flask应用实例
# 修改CORS配置，允许所有来源，包括null来源
CORS(app, resources={r"/*": {"origins": "*"}}, supports_credentials=True)  # 修改CORS配置

# 配置静态文件夹路径
app.static_folder = 'static'
app.static_url_path = '/static'

# 确保数据目录存在
os.makedirs(os.path.dirname(SQLITE_DB_PATH), exist_ok=True)

# 初始化SQLite数据库
def init_sqlite_db():
    """创建SQLite数据库表结构"""
    try:
        conn = sqlite3.connect(SQLITE_DB_PATH)
        cursor = conn.cursor()
        
        # 创建mind_maps表
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS mind_maps (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            subject_name TEXT NOT NULL UNIQUE,
            map_data TEXT NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
        ''')
        
        conn.commit()
        cursor.close()
        conn.close()
        return True, "SQLite数据库初始化成功"
    except Exception as e:
        return False, f"SQLite数据库初始化失败: {str(e)}"

# 测试数据库连接
def test_db_connection():
    """测试与数据库的连接，返回(布尔值, 字符串消息, 数据库类型)"""
    global DATABASE_TYPE
    
    # 尝试连接MySQL
    if MYSQL_AVAILABLE and DATABASE_TYPE == "mysql":
        try:
            print(f"尝试连接到宝塔MySQL: {MYSQL_CONFIG['host']}:{MYSQL_CONFIG.get('port', 3306)}, 用户: {MYSQL_CONFIG['user']}, 数据库: {MYSQL_CONFIG['database']}")
            conn = mysql.connector.connect(**MYSQL_CONFIG)
            if conn.is_connected():
                print(f"宝塔MySQL连接成功: 服务器版本 {conn.get_server_info()}")
                cursor = conn.cursor()
                cursor.execute("SHOW TABLES")
                tables = cursor.fetchall()
                print(f"数据库中的表: {tables}")
                cursor.close()
                conn.close()
                return True, "宝塔MySQL数据库连接成功", "mysql"
        except Exception as e:
            error_message = f"宝塔MySQL连接失败: {str(e)}"
            print(error_message)
            print(f"配置: host={MYSQL_CONFIG['host']}, user={MYSQL_CONFIG['user']}, database={MYSQL_CONFIG['database']}")
            
            # 如果强制使用MySQL但连接失败，则返回错误状态
            if DATABASE_TYPE == "mysql":
                return False, f"宝塔MySQL连接失败: {str(e)}", "mysql"
    
    # 如果不强制使用MySQL或MYSQL_AVAILABLE为False
    if DATABASE_TYPE == "sqlite":
        success, message = init_sqlite_db()
        return success, f"使用SQLite数据库: {message}", "sqlite"
    else:
        # 默认返回MySQL失败状态
        return False, "MySQL不可用且未配置使用SQLite", "unknown"

# 保存知识导图数据到数据库
def save_mindmap_to_db(subject_name, map_data):
    """
    将知识导图数据保存到数据库中
    
    Args:
        subject_name (str): 学科名称，如"民法"、"刑法"
        map_data (dict): 解析后的知识导图JSON数据
        
    Returns:
        dict: 包含操作结果的字典，格式为 {"success": bool, "message": str, "id": int}
    """
    result = {"success": False, "message": "", "id": None}
    
    # 将map_data字典转换为JSON字符串
    map_data_json = json.dumps(map_data, ensure_ascii=False)
    
    # 根据数据库类型执行不同的操作
    if DATABASE_TYPE == "mysql" and MYSQL_AVAILABLE:
        try:
            # 连接到MySQL数据库
            conn = mysql.connector.connect(**MYSQL_CONFIG)
            cursor = conn.cursor()
            
            # 检查是否已存在该学科的知识导图
            check_sql = "SELECT id FROM mind_maps WHERE subject_name = %s"
            cursor.execute(check_sql, (subject_name,))
            existing_record = cursor.fetchone()
            
            if existing_record:
                # 更新已存在的记录
                update_sql = """
                UPDATE mind_maps 
                SET map_data = %s, updated_at = CURRENT_TIMESTAMP 
                WHERE subject_name = %s
                """
                cursor.execute(update_sql, (map_data_json, subject_name))
                result["id"] = existing_record[0]
                result["message"] = f"已更新'{subject_name}'的知识导图数据"
            else:
                # 插入新记录
                insert_sql = """
                INSERT INTO mind_maps (subject_name, map_data)
                VALUES (%s, %s)
                """
                cursor.execute(insert_sql, (subject_name, map_data_json))
                result["id"] = cursor.lastrowid
                result["message"] = f"已成功保存'{subject_name}'的知识导图数据"
            
            # 提交事务
            conn.commit()
            result["success"] = True
            
        except Exception as e:
            # 捕获MySQL错误
            error_msg = str(e)
            result["message"] = f"MySQL数据库操作失败: {error_msg}"
            print(f"MySQL数据库错误: {error_msg}")
            print(traceback.format_exc())
        finally:
            # 无论如何关闭数据库连接
            if 'conn' in locals() and 'conn' in globals() and conn.is_connected():
                cursor.close()
                conn.close()
    else:
        # 使用SQLite
        try:
            conn = sqlite3.connect(SQLITE_DB_PATH)
            cursor = conn.cursor()
            
            # 检查是否已存在该学科的知识导图
            check_sql = "SELECT id FROM mind_maps WHERE subject_name = ?"
            cursor.execute(check_sql, (subject_name,))
            existing_record = cursor.fetchone()
            
            current_time = datetime.datetime.now().isoformat()
            
            if existing_record:
                # 更新已存在的记录
                update_sql = """
                UPDATE mind_maps 
                SET map_data = ?, updated_at = ?
                WHERE subject_name = ?
                """
                cursor.execute(update_sql, (map_data_json, current_time, subject_name))
                result["id"] = existing_record[0]
                result["message"] = f"已更新'{subject_name}'的知识导图数据"
            else:
                # 插入新记录
                insert_sql = """
                INSERT INTO mind_maps (subject_name, map_data, created_at, updated_at)
                VALUES (?, ?, ?, ?)
                """
                cursor.execute(insert_sql, (subject_name, map_data_json, current_time, current_time))
                result["id"] = cursor.lastrowid
                result["message"] = f"已成功保存'{subject_name}'的知识导图数据"
            
            # 提交事务
            conn.commit()
            result["success"] = True
            
        except Exception as e:
            # 捕获SQLite错误
            error_msg = str(e)
            result["message"] = f"SQLite数据库操作失败: {error_msg}"
            print(f"SQLite数据库错误: {error_msg}")
            print(traceback.format_exc())
        finally:
            # 无论如何关闭数据库连接
            if 'conn' in locals():
                cursor.close()
                conn.close()
    
    return result

# --- 应用启动时打印诊断信息 ---
print("--- Flask 应用启动诊断 ---")
print(f"试图导入的函数信息: {imported_parse_function_info}")
if parse_opml_function_to_use:
    print(f"将要使用的解析函数来源模块: {inspect.getmodule(parse_opml_function_to_use)}")
    print(f"将要使用的解析函数名称: {parse_opml_function_to_use.__name__}")
    if parse_opml_function_to_use.__name__ == 'placeholder_parser':
        print("注意：当前使用的是内部定义的占位符解析函数。")
    elif parse_opml_function_to_use.__name__ == 'parse_opml_to_json_tree':
        print("注意：当前看起来是导入了名为 parse_opml_to_json_tree 的函数。")
else:
    print("警告：未能成功导入 parse_opml_to_json_tree 函数。")
print("--------------------------")

# 设置允许上传的文件大小 (例如，10MB)
# 1MB = 1 * 1024 * 1024 bytes
# 10MB = 10 * 1024 * 1024 bytes
app.config['MAX_CONTENT_LENGTH'] = 10 * 1024 * 1024

# 定义文件上传的临时保存路径 (可选)
UPLOAD_FOLDER = 'public/uploads/opml_temp' # 确保这个文件夹存在，或者在代码中创建它
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER

# 确保上传文件夹存在
if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)

# 设置允许上传的文件类型
ALLOWED_EXTENSIONS = {'doc', 'docx'}

# 检查文件扩展名是否允许
def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

# 添加根路径处理
@app.route('/')
def index():
    # 测试数据库连接
    db_success, db_message, db_type = test_db_connection()
    
    # 创建一个简单的HTML页面
    html_content = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>法考知识导图 OPML 处理 API</title>
        <style>
            body { 
                font-family: Arial, sans-serif; 
                line-height: 1.6;
                max-width: 800px;
                margin: 0 auto;
                padding: 20px;
            }
            h1 { color: #333; }
            h2 { color: #0066cc; margin-top: 20px; }
            code { 
                background-color: #f5f5f5; 
                padding: 2px 4px; 
                border-radius: 4px;
                font-family: monospace;
            }
            pre {
                background-color: #f5f5f5;
                padding: 10px;
                border-radius: 4px;
                overflow-x: auto;
            }
            .endpoint {
                margin-bottom: 15px;
                border-left: 3px solid #0066cc;
                padding-left: 10px;
            }
            .method {
                font-weight: bold;
                color: #009900;
            }
            .url {
                font-weight: bold;
            }
            .test-db {
                margin-top: 30px;
                padding: 15px;
                background-color: #f8f8f8;
                border-radius: 4px;
                border: 1px solid #ddd;
            }
            .current-db {
                font-weight: bold;
                color: #0066cc;
            }
        </style>
    </head>
    <body>
        <h1>法考知识导图 OPML 处理 API</h1>
        
        <div class="test-db">
            <h3>数据库连接状态</h3>
            <p>
            """
    # 添加数据库连接状态
    if db_success:
        html_content += '<span style="color: green;">✅ ' + db_message + '</span>'
    else:
        html_content += '<span style="color: red;">❌ ' + db_message + '</span>'
    
    html_content += """
            </p>
            <p>当前使用的数据库类型: <span class="current-db">{db_type}</span></p>
        </div>

        <h2>API 端点</h2>
        
        <div class="endpoint">
            <p><span class="method">POST</span> <span class="url">/admin/upload-opml</span></p>
            <p>上传 OPML 文件并进行解析，返回JSON格式的知识树。同时尝试将解析后的数据保存到数据库中。</p>
            <p><strong>参数:</strong></p>
            <ul>
                <li><code>file</code>: OPML 文件 (必须)</li>
                <li><code>subject_name</code>: 学科名称，例如"民法" (可选，如不提供将从OPML中提取)</li>
            </ul>
            <p><strong>示例:</strong></p>
            <pre>curl -X POST -F "file=@民法.opml" -F "subject_name=民法" http://127.0.0.1:5001/admin/upload-opml</pre>
        </div>

        <div class="endpoint">
            <p><span class="method">GET</span> <span class="url">/api/mindmaps/list</span></p>
            <p>获取所有已存储的学科知识导图列表（不包含完整的导图数据）</p>
            <p><strong>示例:</strong></p>
            <pre>curl http://127.0.0.1:5001/api/mindmaps/list</pre>
        </div>

        <div class="endpoint">
            <p><span class="method">GET</span> <span class="url">/api/mindmaps/{{subject}}</span></p>
            <p>获取特定学科的完整知识导图数据</p>
            <p><strong>参数:</strong></p>
            <ul>
                <li><code>{{subject}}</code>: URL中的学科名称，例如"民法"</li>
            </ul>
            <p><strong>示例:</strong></p>
            <pre>curl http://127.0.0.1:5001/api/mindmaps/民法</pre>
        </div>

        <h2>解析函数导入状态</h2>
        <pre>{imported_parse_function_info}</pre>
        
    </body>
    </html>
    """.format(db_type=db_type.upper(), imported_parse_function_info=imported_parse_function_info)
    
    return render_template_string(html_content)

# API 端点，用于上传OPML文件
# 路径名使用小写字母和连字符，例如 /admin/upload-opml
@app.route('/admin/upload-opml', methods=['POST'])
def upload_opml_file_endpoint():
    # --- 端点调用时打印诊断信息 ---
    endpoint_parser_func = parse_opml_function_to_use # 获取当前上下文中实际指向的函数
    print("\n--- 端点 /admin/upload-opml 调用诊断 ---")
    if endpoint_parser_func:
        print(f"端点内实际调用的解析函数来源模块: {inspect.getmodule(endpoint_parser_func)}")
        print(f"端点内实际调用的解析函数名称: {endpoint_parser_func.__name__}")
        if endpoint_parser_func.__name__ == 'placeholder_parser':
            print("端点注意：调用的是内部定义的占位符解析函数。")
        elif endpoint_parser_func.__name__ == 'parse_opml_to_json_tree':
            print("端点注意：调用的是名为 parse_opml_to_json_tree 的函数。")
    else:
        print("端点错误：在端点内，parse_opml_function_to_use 未定义!")
        return jsonify({"error": "服务器配置错误：解析函数未初始化"}), 500
    print("------------------------------------")

    # 1. 检查请求中是否包含文件部分
    if 'file' not in request.files:
        return jsonify({"error": "请求中未找到文件部分 ('file')"}), 400 # 返回错误信息和400状态码

    uploaded_file = request.files['file'] # 获取上传的文件对象

    # 2. 检查文件名是否为空 (用户可能没有选择文件就提交了表单)
    if uploaded_file.filename == '':
        return jsonify({"error": "未选择任何文件"}), 400

    # 3. 获取学科名称 (来自表单数据)
    subject_name = request.form.get('subject_name') # 'subject_name' 对应前端表单中的字段名
    if not subject_name:
        return jsonify({"error": "未提供学科名称 (表单字段 'subject_name' 未找到)"}), 400

    # 4. 检查文件类型 (可选，但推荐)
    # 你可以检查文件名后缀是否为 .opml
    if not uploaded_file.filename.lower().endswith('.opml'):
        return jsonify({"error": "文件类型无效，请上传有效的OPML文件 (以 .opml 结尾)"}), 400
        
    # 文件大小校验已由 app.config['MAX_CONTENT_LENGTH'] 处理
    # 如果文件太大，Flask 会自动返回一个 413 Request Entity Too Large 错误

    # 至此，我们已经获取了文件和学科名称
    # 接下来是读取文件内容并调用解析函数

    try:
        # 5. 读取文件内容
        # uploaded_file.read() 会读取整个文件内容到内存
        # 对于非常大的文件，可以考虑流式处理或先保存到临时文件再读取
        opml_file_content_bytes = uploaded_file.read()
        opml_file_content_string = opml_file_content_bytes.decode('utf-8') # OPML 通常是 UTF-8 编码

        # (可选) 如果你配置了 UPLOAD_FOLDER 并想临时保存文件:
        # filename = os.path.join(app.config['UPLOAD_FOLDER'], uploaded_file.filename)
        # uploaded_file.save(filename) # 这会再次读取文件流，如果已经 read() 过，可能需要重置流指针或重新获取文件
        # with open(filename, 'r', encoding='utf-8') as f:
        #    opml_file_content_string = f.read()
        # os.remove(filename) # 解析完后删除临时文件

        # 6. 调用OPML解析函数 (子任务2的成果)
        # 注意：你需要确保 parse_opml_to_json_tree 函数已正确定义并导入
        parsed_data_from_opml = endpoint_parser_func(opml_file_content_string, subject_name)

        # 新增: 打印解析结果以供调试
        print(f"DEBUG: 解析函数返回的结果 (parsed_data_from_opml): {parsed_data_from_opml}")

        if isinstance(parsed_data_from_opml, dict) and parsed_data_from_opml.get("error"):
            actual_error_message = parsed_data_from_opml.get("error", "未提供具体的解析错误信息")
            app.logger.warning(f"OPML解析为学科 '{subject_name}' 时返回错误: {actual_error_message}")
        return jsonify({
                "message": "文件上传但解析失败",
                "uploaded_filename": uploaded_file.filename,
                "subject_processed": subject_name,
                    "parser_error_detail": actual_error_message # 使用新变量确保错误信息被传递
            }), 400

        # 7. 将解析后的数据保存到数据库
        db_result = save_mindmap_to_db(subject_name, parsed_data_from_opml)
        
        # 8. 返回解析后的JSON数据、存储状态和成功消息
        response_data = {
            "message": "文件上传成功并已解析",
            "uploaded_filename": uploaded_file.filename,
            "subject_processed": subject_name,
            "parsed_opml_data": parsed_data_from_opml,
            "database_storage": db_result
        }
        
        if not db_result["success"]:
            app.logger.warning(f"数据库存储失败: {db_result['message']}")
            # 即使数据库存储失败，我们仍然返回解析成功的结果，但添加一个警告
            response_data["warnings"] = ["数据已成功解析，但未能存储到数据库。这不影响当前操作，但可能影响后续功能。"]
        
        return jsonify(response_data), 200 # 200 OK 表示成功

    except UnicodeDecodeError:
        app.logger.error(f"文件解码错误，文件名: {uploaded_file.filename}")
        return jsonify({"error": "文件编码错误，请确保OPML文件为UTF-8编码"}), 400
    except Exception as e:
        app.logger.error(f"处理文件 '{uploaded_file.filename}' 时发生未知服务器错误: {str(e)}", exc_info=True)
        return jsonify({"error": f"处理文件时发生服务器内部错误，请联系管理员。"}), 500 # 500 Internal Server Error

# 添加一个新的API端点，用于获取所有学科知识导图列表
@app.route('/api/mindmaps/list', methods=['GET'])
def list_mindmaps_endpoint():
    """
    返回所有已存储在数据库中的学科知识导图的简要信息列表。
    不返回完整的知识导图数据，只返回学科名称、创建时间和更新时间等元数据。
    """
    mindmaps = []
    
    try:
        if DATABASE_TYPE == "mysql" and MYSQL_AVAILABLE:
            # 使用MySQL
            conn = mysql.connector.connect(**MYSQL_CONFIG)
            cursor = conn.cursor(dictionary=True)  # 返回字典格式的结果
            
            # 查询所有学科的基本信息，不包括完整的map_data
            sql = """
            SELECT id, subject_name, created_at, updated_at 
            FROM mind_maps 
            ORDER BY updated_at DESC
            """
            
            cursor.execute(sql)
            mindmaps = cursor.fetchall()
            
            # 关闭游标和连接
            cursor.close()
            conn.close()
            
            # 转换datetime对象为ISO格式字符串，以便JSON序列化
            for mindmap in mindmaps:
                if 'created_at' in mindmap and mindmap['created_at']:
                    mindmap['created_at'] = mindmap['created_at'].isoformat()
                if 'updated_at' in mindmap and mindmap['updated_at']:
                    mindmap['updated_at'] = mindmap['updated_at'].isoformat()
        else:
            # 使用SQLite
            conn = sqlite3.connect(SQLITE_DB_PATH)
            conn.row_factory = sqlite3.Row  # 使结果可以通过列名访问
            cursor = conn.cursor()
            
            # 查询所有学科的基本信息，不包括完整的map_data
            sql = """
            SELECT id, subject_name, created_at, updated_at 
            FROM mind_maps 
            ORDER BY updated_at DESC
            """
            
            cursor.execute(sql)
            rows = cursor.fetchall()
            
            # 将sqlite3.Row对象转换为字典
            for row in rows:
                mindmap = {}
                for key in row.keys():
                    mindmap[key] = row[key]
                mindmaps.append(mindmap)
            
            # 关闭游标和连接
            cursor.close()
            conn.close()
        
        return jsonify({
            'success': True,
            'mindmaps': mindmaps,
            'count': len(mindmaps),
            'database_type': DATABASE_TYPE
        })

    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'数据库错误: {str(e)}',
            'mindmaps': [],
            'database_type': DATABASE_TYPE
        }), 500

# 添加一个新的API端点，用于获取特定学科的知识导图数据
@app.route('/api/mindmaps/<subject>', methods=['GET'])
def get_mindmap_endpoint(subject):
    """
    返回指定学科的知识导图数据，包括完整的导图结构
    """
    mindmap = None
    
    try:
        if DATABASE_TYPE == "mysql" and MYSQL_AVAILABLE:
            # 使用MySQL
            conn = mysql.connector.connect(**MYSQL_CONFIG)
            cursor = conn.cursor(dictionary=True)  # 返回字典格式的结果
            
            # 查询特定学科的知识导图数据
            sql = """
            SELECT id, subject_name, map_data, created_at, updated_at 
            FROM mind_maps 
            WHERE subject_name = %s
            """
            
            cursor.execute(sql, (subject,))
            mindmap = cursor.fetchone()
            
            # 关闭游标和连接
            cursor.close()
            conn.close()
            
            # 转换datetime对象为ISO格式字符串，以便JSON序列化
            if mindmap:
                if 'created_at' in mindmap and mindmap['created_at']:
                    mindmap['created_at'] = mindmap['created_at'].isoformat()
                if 'updated_at' in mindmap and mindmap['updated_at']:
                    mindmap['updated_at'] = mindmap['updated_at'].isoformat()
        else:
            # 使用SQLite
            conn = sqlite3.connect(SQLITE_DB_PATH)
            conn.row_factory = sqlite3.Row  # 使结果可以通过列名访问
            cursor = conn.cursor()
            
            # 查询特定学科的知识导图数据
            sql = """
            SELECT id, subject_name, map_data, created_at, updated_at 
            FROM mind_maps 
            WHERE subject_name = ?
            """
            
            cursor.execute(sql, (subject,))
            row = cursor.fetchone()
            
            # 将sqlite3.Row对象转换为字典
            if row:
                mindmap = {}
                for key in row.keys():
                    mindmap[key] = row[key]
            
            # 关闭游标和连接
            cursor.close()
            conn.close()
        
        if not mindmap:
            return jsonify({
                'success': False,
                'message': f'未找到学科: {subject}',
                'mindmap': None,
                'database_type': DATABASE_TYPE
            }), 404
        
        # 将map_data从JSON字符串转换回Python字典
        try:
            mindmap['map_data'] = json.loads(mindmap['map_data'])
        except json.JSONDecodeError as e:
            return jsonify({
                'success': False,
                'message': f'解析知识导图数据失败: {str(e)}',
                'mindmap': None,
                'database_type': DATABASE_TYPE
            }), 500
        
        return jsonify({
            'success': True,
            'mindmap': mindmap,
            'database_type': DATABASE_TYPE
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'数据库错误: {str(e)}',
            'mindmap': None,
            'database_type': DATABASE_TYPE
        }), 500

@app.route('/admin/api/upload_word', methods=['POST'])
def upload_word():
    # 检查是否有文件被上传
    if 'file' not in request.files:
        return jsonify({
            'success': False,
            'message': '没有选择文件'
        }), 400
    
    # 获取学科分类（如果提供）
    subject_area = request.form.get('subject_area', '')
    
    file = request.files['file']
    
    # 检查文件名是否为空
    if file.filename == '':
        return jsonify({
            'success': False,
            'message': '没有选择文件'
        }), 400
    
    # 检查文件类型是否允许
    if not allowed_file(file.filename):
        return jsonify({
            'success': False,
            'message': '只允许上传.doc或.docx格式的文件'
        }), 400
    
    # 生成安全的文件名并保存文件
    filename = secure_filename(file.filename)
    # 添加唯一标识符，避免文件名冲突
    file_id = str(uuid.uuid4())
    
    # 修复文件扩展名处理逻辑
    try:
        file_extension = filename.rsplit('.', 1)[1].lower()
    except IndexError:
        # 如果文件名没有扩展名，默认为docx
        file_extension = 'docx'
        
    new_filename = f"{file_id}.{file_extension}"
    
    # 确保上传文件夹存在
    UPLOAD_FOLDER = 'uploads'
    if not os.path.exists(UPLOAD_FOLDER):
        os.makedirs(UPLOAD_FOLDER)
    
    file_path = os.path.join(UPLOAD_FOLDER, new_filename)
    
    try:
        # 保存文件
        file.save(file_path)
        
        # 确定文档类型代码
        doc_type = 1 if file_extension == 'doc' else 3 if file_extension == 'docx' else 4
        
        # 创建knowledge_documents表（如果不存在）
        if DATABASE_TYPE == "mysql" and MYSQL_AVAILABLE:
            try:
                conn = mysql.connector.connect(**MYSQL_CONFIG)
                cursor = conn.cursor()
                
                # 检查表是否存在
                cursor.execute("""
                CREATE TABLE IF NOT EXISTS knowledge_documents (
                    doc_id VARCHAR(36) PRIMARY KEY,
                    doc_name VARCHAR(80) NOT NULL,
                    doc_type TINYINT NOT NULL COMMENT '1: doc, 2: text, 3: docx, 4: other',
                    file_path VARCHAR(150) NOT NULL,
                    subject_area VARCHAR(50),
                    upload_date DATETIME NOT NULL,
                    is_active TINYINT(1) NOT NULL DEFAULT 1
                )
                """)
                conn.commit()
                
                # 记录到MySQL数据库
                cursor.execute(
                    "INSERT INTO knowledge_documents (doc_id, doc_name, doc_type, file_path, subject_area, upload_date) VALUES (%s, %s, %s, %s, %s, %s)",
                    (file_id, filename, doc_type, file_path, subject_area, datetime.datetime.now())
                )
                conn.commit()
                cursor.close()
                conn.close()
            except Exception as e:
                print(f"MySQL数据库操作失败: {str(e)}")
                # 如果MySQL失败，则使用SQLite作为备份
                conn = sqlite3.connect(SQLITE_DB_PATH)
                cursor = conn.cursor()
                
                # 创建表（如果不存在）
                cursor.execute('''
                CREATE TABLE IF NOT EXISTS knowledge_documents (
                    doc_id TEXT PRIMARY KEY,
                    doc_name TEXT NOT NULL,
                    doc_type INTEGER NOT NULL,
                    file_path TEXT NOT NULL,
                    subject_area TEXT,
                    upload_date TEXT NOT NULL,
                    is_active INTEGER DEFAULT 1
                )
                ''')
                conn.commit()
                
                # 记录到SQLite数据库
                cursor.execute(
                    "INSERT INTO knowledge_documents (doc_id, doc_name, doc_type, file_path, subject_area, upload_date) VALUES (?, ?, ?, ?, ?, ?)",
                    (file_id, filename, doc_type, file_path, subject_area, datetime.datetime.now().isoformat())
                )
                conn.commit()
                cursor.close()
                conn.close()
        else:
            # 直接使用SQLite
            conn = sqlite3.connect(SQLITE_DB_PATH)
            cursor = conn.cursor()
            
            # 创建表（如果不存在）
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS knowledge_documents (
                doc_id TEXT PRIMARY KEY,
                doc_name TEXT NOT NULL,
                doc_type INTEGER NOT NULL,
                file_path TEXT NOT NULL,
                subject_area TEXT,
                upload_date TEXT NOT NULL,
                is_active INTEGER DEFAULT 1
            )
            ''')
            conn.commit()
            
            # 记录到SQLite数据库
            cursor.execute(
                "INSERT INTO knowledge_documents (doc_id, doc_name, doc_type, file_path, subject_area, upload_date) VALUES (?, ?, ?, ?, ?, ?)",
                (file_id, filename, doc_type, file_path, subject_area, datetime.datetime.now().isoformat())
            )
            conn.commit()
            cursor.close()
            conn.close()
        
        return jsonify({
            'success': True,
            'message': '文件上传成功',
            'data': {
                'file_id': file_id,
                'original_filename': filename,
                'file_path': file_path,
                'subject_area': subject_area
            }
        }), 200
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'文件上传失败: {str(e)}'
        }), 500

# 获取已上传文档列表的API
@app.route('/admin/api/documents', methods=['GET'])
def get_documents():
    try:
        if DATABASE_TYPE == "mysql" and MYSQL_AVAILABLE:
            try:
                conn = mysql.connector.connect(**MYSQL_CONFIG)
                cursor = conn.cursor(dictionary=True)  # 使结果可以通过列名访问
                
                # 确保表存在
                cursor.execute("""
                CREATE TABLE IF NOT EXISTS knowledge_documents (
                    doc_id VARCHAR(36) PRIMARY KEY,
                    doc_name VARCHAR(80) NOT NULL,
                    doc_type TINYINT NOT NULL COMMENT '1: doc, 2: text, 3: docx, 4: other',
                    file_path VARCHAR(150) NOT NULL,
                    subject_area VARCHAR(50),
                    upload_date DATETIME NOT NULL,
                    is_active TINYINT(1) NOT NULL DEFAULT 1
                )
                """)
                conn.commit()
                
                cursor.execute("SELECT * FROM knowledge_documents WHERE is_active = 1 ORDER BY upload_date DESC")
                documents = cursor.fetchall()
                cursor.close()
                conn.close()
            except Exception as e:
                print(f"MySQL查询失败: {str(e)}，尝试使用SQLite")
                # 如果MySQL失败，则使用SQLite作为备份
                conn = sqlite3.connect(SQLITE_DB_PATH)
                conn.row_factory = sqlite3.Row  # 这使结果可以通过列名访问
                cursor = conn.cursor()
                
                # 确保SQLite表存在
                cursor.execute('''
                CREATE TABLE IF NOT EXISTS knowledge_documents (
                    doc_id TEXT PRIMARY KEY,
                    doc_name TEXT NOT NULL,
                    doc_type INTEGER NOT NULL,
                    file_path TEXT NOT NULL,
                    subject_area TEXT,
                    upload_date TEXT NOT NULL,
                    is_active INTEGER DEFAULT 1
                )
                ''')
                conn.commit()
                
                cursor.execute("SELECT * FROM knowledge_documents WHERE is_active = 1 ORDER BY upload_date DESC")
                documents = [dict(row) for row in cursor.fetchall()]
                cursor.close()
                conn.close()
        else:
            # 直接使用SQLite
            conn = sqlite3.connect(SQLITE_DB_PATH)
            conn.row_factory = sqlite3.Row  # 这使结果可以通过列名访问
            cursor = conn.cursor()
            
            # 确保SQLite表存在
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS knowledge_documents (
                doc_id TEXT PRIMARY KEY,
                doc_name TEXT NOT NULL,
                doc_type INTEGER NOT NULL,
                file_path TEXT NOT NULL,
                subject_area TEXT,
                upload_date TEXT NOT NULL,
                is_active INTEGER DEFAULT 1
            )
            ''')
            conn.commit()
            
            cursor.execute("SELECT * FROM knowledge_documents WHERE is_active = 1 ORDER BY upload_date DESC")
            documents = [dict(row) for row in cursor.fetchall()]
            cursor.close()
            conn.close()
        
        return jsonify({
            'success': True,
            'message': '获取文档列表成功',
            'data': {
                'documents': documents
            }
        }), 200
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'获取文档列表失败: {str(e)}'
        }), 500

@app.route('/admin/api/extract_text', methods=['GET'])
def extract_document_text():
    """
    从数据库中获取文档信息并提取其中的文本
    请求参数：
        doc_id: 文档ID
    返回：
        包含提取文本的JSON响应
    """
    doc_id = request.args.get('doc_id')
    
    if not doc_id:
        return jsonify({
            'success': False,
            'message': '缺少文档ID参数'
        }), 400
    
    try:
        # 从数据库查询文档信息
        file_path = None
        doc_name = None
        
        if DATABASE_TYPE == "mysql" and MYSQL_AVAILABLE:
            try:
                conn = mysql.connector.connect(**MYSQL_CONFIG)
                cursor = conn.cursor(dictionary=True)
                cursor.execute("SELECT file_path, doc_name FROM knowledge_documents WHERE doc_id = %s AND is_active = 1", (doc_id,))
                document = cursor.fetchone()
                cursor.close()
                conn.close()
                
                if document:
                    file_path = document['file_path']
                    doc_name = document['doc_name']
            except Exception as e:
                print(f"MySQL查询失败: {str(e)}，尝试使用SQLite")
                # 如果MySQL失败，使用SQLite作为备份
                conn = sqlite3.connect(SQLITE_DB_PATH)
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                cursor.execute("SELECT file_path, doc_name FROM knowledge_documents WHERE doc_id = ? AND is_active = 1", (doc_id,))
                document = cursor.fetchone()
                cursor.close()
                conn.close()
                
                if document:
                    file_path = document['file_path']
                    doc_name = document['doc_name']
        else:
            # 直接使用SQLite
            conn = sqlite3.connect(SQLITE_DB_PATH)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            cursor.execute("SELECT file_path, doc_name FROM knowledge_documents WHERE doc_id = ? AND is_active = 1", (doc_id,))
            document = cursor.fetchone()
            cursor.close()
            conn.close()
            
            if document:
                file_path = document['file_path']
                doc_name = document['doc_name']
        
        # 如果数据库中找不到文档，尝试直接从文件系统中查找
        if not file_path:
            # 检查uploads目录中是否有该ID的文件
            for ext in ['docx', 'doc']:
                possible_path = os.path.join('uploads', f"{doc_id}.{ext}")
                if os.path.exists(possible_path):
                    file_path = possible_path
                    doc_name = f"{doc_id}.{ext}"
                    print(f"在文件系统中找到文档: {file_path}")
                    break
            
            if not file_path:
                return jsonify({
                    'success': False,
                    'message': f'未找到ID为{doc_id}的文档'
                }), 404
        
        # 检查文件是否存在
        if not os.path.exists(file_path):
            return jsonify({
                'success': False,
                'message': f'文件不存在: {file_path}'
            }), 404
        
        # 提取文本
        if not DOCX_PARSER_AVAILABLE:
            return jsonify({
                'success': False,
                'message': '文本提取模块未正确加载，无法处理Word文档'
            }), 500
        
        try:
            extracted_text = extract_text_from_word(file_path)
            text_length = len(extracted_text)
            
            return jsonify({
                'success': True,
                'message': '文本提取成功',
                'data': {
                    'doc_id': doc_id,
                    'doc_name': doc_name,
                    'text': extracted_text,  # 返回完整文本，而不是预览
                    'text_length': text_length,
                    'file_path': file_path
                }
            }), 200
        except Exception as e:
            return jsonify({
                'success': False,
                'message': f'文本提取失败: {str(e)}'
            }), 500
    
    except Exception as e:
        return jsonify({
            'success': False,
            'message': f'服务器错误: {str(e)}'
        }), 500

@app.route('/admin/api/segment_text', methods=['POST'])
def segment_document_text():
    """
    接收一段文本并进行分段处理
    请求参数：
    - text: 要分段的文本
    - strategy: 分段策略，可选值有 fixed_length（固定长度）、paragraph（段落）、combined（组合）、
               smart（智能混合）、legal_structure（法律结构）
    - chunk_size: 文本块大小，当strategy=fixed_length/combined/smart/legal_structure时使用
    - overlap: 重叠长度，当strategy=fixed_length/combined/smart时使用
    """
    if not TEXT_SEGMENTATION_AVAILABLE:
        return jsonify({
            "success": False,
            "message": "文本分段模块未加载，无法处理请求",
            "chunks": []
        })
    
    try:
        # 获取请求参数
        data = request.get_json()
        if not data:
            return jsonify({
                "success": False,
                "message": "请求缺少必要的JSON数据",
                "chunks": []
            })
        
        text = data.get('text', '')
        strategy = data.get('strategy', 'fixed_length')
        chunk_size = int(data.get('chunk_size', 500))
        overlap = int(data.get('overlap', 50))
        
        if not text:
            return jsonify({
                "success": False,
                "message": "未提供文本内容",
                "chunks": []
            })
        
        print(f"接收到分段请求，策略：{strategy}，块大小：{chunk_size}，重叠：{overlap}")
        
        # 根据不同策略调用分段函数
        if strategy == 'fixed_length' or strategy == 'paragraph':
            chunks = segment_text(text, strategy, chunk_size, overlap)
            # 返回分段结果（普通格式）
            return jsonify({
                "success": True,
                "message": f"文本已使用 {strategy} 策略成功分段为 {len(chunks)} 块",
                "chunks": chunks,
                "total_chunks": len(chunks),
                "strategy": strategy,
                "chunk_size": chunk_size,
                "overlap": overlap
            })
        elif strategy == 'combined':
            chunks = segment_text_combined(text, chunk_size, overlap)
            # 返回分段结果（普通格式）
            return jsonify({
                "success": True,
                "message": f"文本已使用 {strategy} 策略成功分段为 {len(chunks)} 块",
                "chunks": chunks,
                "total_chunks": len(chunks),
                "strategy": strategy,
                "chunk_size": chunk_size,
                "overlap": overlap
            })
        elif strategy == 'smart':
            chunks = segment_text_smart(text, chunk_size, overlap)
            # 返回分段结果（普通格式）
            return jsonify({
                "success": True,
                "message": f"文本已使用 {strategy} 策略成功分段为 {len(chunks)} 块",
                "chunks": chunks,
                "total_chunks": len(chunks),
                "strategy": strategy,
                "chunk_size": chunk_size,
                "overlap": overlap
            })
        elif strategy == 'legal_structure':
            # 法律结构分段返回文本段落和元数据
            segments, metadata = segment_text_legal_structure(text, chunk_size=chunk_size)
            
            # 组合段落和元数据为结构化结果
            structured_chunks = []
            for i, (segment, meta) in enumerate(zip(segments, metadata)):
                structured_chunks.append({
                    "content": segment,
                    "metadata": meta
                })
            
            # 返回带有结构化元数据的分段结果
            return jsonify({
                "success": True,
                "message": f"文本已使用 {strategy} 策略成功分段为 {len(segments)} 块",
                "chunks": structured_chunks,  # 带有元数据的结构化文本块
                "total_chunks": len(segments),
                "strategy": strategy,
                "chunk_size": chunk_size
            })
        else:
            return jsonify({
                "success": False,
                "message": f"不支持的分段策略: {strategy}",
                "chunks": []
            })
        
    except Exception as e:
        error_message = f"文本分段处理失败: {str(e)}"
        print(error_message)
        print(traceback.format_exc())
        
        return jsonify({
            "success": False,
            "message": error_message,
            "chunks": []
        })

def segment_text_legal_structure(full_text, chunk_size=800):
    """
    使用法律结构智能分段器处理文本
    
    Args:
        full_text: 要分段的文本内容
        chunk_size: 最大分段大小
        
    Returns:
        tuple: (分段列表, 元数据列表)
    """
    # 导入text_segmentation模块中的同名函数
    from text_segmentation import segment_text_legal_structure as text_seg_legal
    
    # 调用实际的分段函数
    return text_seg_legal(full_text, chunk_size=chunk_size)

# 文档向量化API
@app.route('/admin/api/vectorize', methods=['POST'])
def vectorize_document():
    """
    对上传的文档进行向量化处理
    
    请求参数:
    - doc_id: 文档ID
    
    返回:
    - 成功或失败的JSON消息
    """
    try:
        # 获取请求参数
        data = request.get_json()
        if not data:
            return jsonify({
                "success": False,
                "message": "请求缺少必要的JSON数据"
            }), 400
        
        doc_id = data.get('doc_id')
        chunk_size = data.get('chunk_size', None)  # 现在使用智能分段，这个参数被忽略
        
        if not doc_id:
            return jsonify({
                "success": False,
                "message": "缺少文档ID参数"
            }), 400
        
        # 查询文档信息
        if DATABASE_TYPE == "mysql" and MYSQL_AVAILABLE:
            conn = mysql.connector.connect(**MYSQL_CONFIG)
            cursor = conn.cursor(dictionary=True)
            
            query = "SELECT * FROM documents WHERE doc_id = %s"
            cursor.execute(query, (doc_id,))
            document = cursor.fetchone()
            
            cursor.close()
            conn.close()
        else:
            # 使用SQLite
            conn = sqlite3.connect(SQLITE_DB_PATH)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            query = "SELECT * FROM documents WHERE doc_id = ?"
            cursor.execute(query, (doc_id,))
            document = dict(cursor.fetchone()) if cursor.fetchone() else None
            
            cursor.close()
            conn.close()
                
        if not document:
            return jsonify({
                "success": False,
                "message": f"未找到ID为{doc_id}的文档"
            }), 404
        
        # 获取文档路径和名称
        file_path = document.get('file_path')
        doc_name = document.get('doc_name', os.path.basename(file_path))
        
        # 检查文件是否存在
        if not os.path.exists(file_path):
            return jsonify({
                "success": False,
                "message": f"文件不存在: {file_path}"
            }), 404
            
        # 从环境变量中获取API密钥
        api_key = os.environ.get("DEEPSEEK_API_KEY")
        
        # 检查API密钥是否存在
        if not api_key:
            return jsonify({
                "success": False,
                "message": "DeepSeek API密钥未设置，无法执行向量化，请在.env文件中设置DEEPSEEK_API_KEY"
            }), 500
            
        # 初始化进度状态
        processing_status[doc_id] = {
            "status": "processing",
            "progress": 0,
            "message": "正在准备处理..."
        }
        
        # 定义后台处理函数
        def process_document_in_background(doc_id, file_path, doc_name, chunk_size, api_key):
            try:
                # 更新状态：开始提取文本
                processing_status[doc_id] = {
                    "status": "processing",
                    "progress": 5,
                    "message": "正在从文档中提取文本..."
                }
                
                # 提取文本
                extracted_text = extract_text_from_word(file_path)
                if not extracted_text:
                    processing_status[doc_id] = {
                        "status": "failed",
                        "progress": 0,
                        "message": "无法从文档中提取文本"
                    }
                    return
                
                # 更新状态：开始分段
                processing_status[doc_id] = {
                    "status": "processing",
                    "progress": 20,
                    "message": "正在进行智能分段..."
                }
                
                # 使用法律文档智能分段
                segments = segment_text_legal_structure(extracted_text)
                if not segments:
                    processing_status[doc_id] = {
                        "status": "failed",
                        "progress": 0,
                        "message": "文本分段失败"
                    }
                    return
                
                # 更新状态：分段完成
                processing_status[doc_id] = {
                    "status": "processing",
                    "progress": 40,
                    "message": f"分段完成，共{len(segments)}个文本段落"
                }
                
                # 准备元数据
                metadata_list = [{} for _ in segments]  # 简单元数据
                
                # 更新状态：开始向量化
                processing_status[doc_id] = {
                    "status": "processing",
                    "progress": 50,
                    "message": "正在生成向量嵌入..."
                }
        
                # 初始化向量存储，传递API密钥
                if DATABASE_TYPE == "mysql" and MYSQL_AVAILABLE:
                    vector_store = VectorStore(
                        database_type="mysql",
                        mysql_config=MYSQL_CONFIG,
                        api_key=api_key,
                        embedding_model="deepseek-embed"  # 更新为DeepSeek的嵌入模型
                    )
                else:
                    # 使用SQLite作为备用
                    vector_store = VectorStore(
                        database_type="sqlite",
                        api_key=api_key,
                        embedding_model="deepseek-embed"  # 更新为DeepSeek的嵌入模型
                    )
        
                # 分批处理文本段落，避免一次性处理过多段落导致卡顿
                total_segments = len(segments)
                batch_size = 50  # 每批处理50个段落
                
                # 确保至少有一个批次
                num_batches = max(1, (total_segments + batch_size - 1) // batch_size)
                
                for batch_idx in range(num_batches):
                    start_idx = batch_idx * batch_size
                    end_idx = min(start_idx + batch_size, total_segments)
                    
                    batch_segments = segments[start_idx:end_idx]
                    batch_metadata = metadata_list[start_idx:end_idx]
                    
                    # 处理当前批次的段落
                    for i, (segment, metadata) in enumerate(zip(batch_segments, batch_metadata)):
                        # 计算总体进度
                        overall_idx = start_idx + i
                        progress = 60 + int((overall_idx / total_segments) * 35)
                        processing_status[doc_id]["progress"] = progress
                        processing_status[doc_id]["message"] = f"正在处理第 {overall_idx+1}/{total_segments} 个文本段落..."
                        
                        # 避免线程占用过多CPU
                        if i % 10 == 0:
                            time.sleep(0.05)
                    
                    # 批量存储当前批次的向量
                    success = vector_store.store_text_chunks(
                        doc_id=doc_id,
                        texts=batch_segments,
                        metadata_list=batch_metadata,
                        source_document_name=doc_name
                    )
                    
                    if not success:
                        processing_status[doc_id] = {
                            "status": "failed",
                            "progress": 95,
                            "message": "向量化存储失败"
                        }
                        return
                    
                    # 更新批次处理进度
                    processing_status[doc_id]["progress"] = 95 + int((batch_idx + 1) / num_batches * 5)
                    processing_status[doc_id]["message"] = f"正在保存第 {batch_idx+1}/{num_batches} 批向量数据..."
                
                # 更新状态：完成
                processing_status[doc_id] = {
                    "status": "completed",
                    "progress": 100,
                    "message": f"成功对文档'{doc_name}'进行智能分段和向量化处理并存储",
                    "segments_count": len(segments),
                    "total_characters": len(extracted_text)
                }
                
            except Exception as e:
                # 处理过程中出现异常
                processing_status[doc_id] = {
                    "status": "failed",
                    "progress": 0,
                    "message": f"处理失败: {str(e)}"
                }
        
        # 启动后台线程进行处理
        threading.Thread(
            target=process_document_in_background,
            args=(doc_id, file_path, doc_name, chunk_size, api_key)
        ).start()
        
        # 立即返回，后台继续处理
        return jsonify({
            "success": True,
            "message": "向量化处理已开始，请通过状态API获取进度",
            "data": {
                "doc_id": doc_id,
                "status_url": f"/admin/api/processing_status?doc_id={doc_id}"
            }
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "message": f"处理失败: {str(e)}"
        }), 500

# 添加向量搜索API
@app.route('/api/search', methods=['POST'])
def search_documents():
    """
    基于向量相似度搜索文档
    
    请求参数:
    - query: 搜索查询文本
    - top_k: 返回的结果数量（可选，默认5）
    - filters: 过滤条件，如 {"law_name": "中华人民共和国宪法"} （可选）
    
    返回:
    - 相似文档列表的JSON
    """
    if not VECTOR_STORE_AVAILABLE:
        return jsonify({
            "success": False,
            "message": "向量存储模块未加载，无法处理请求",
            "results": []
        }), 500
    
    try:
        # 获取请求参数
        data = request.get_json()
        if not data:
            return jsonify({
                "success": False,
                "message": "请求缺少必要的JSON数据",
                "results": []
            }), 400
        
        query = data.get('query')
        top_k = int(data.get('top_k', 5))
        filters = data.get('filters', {})
        
        if not query:
            return jsonify({
                "success": False,
                "message": "缺少搜索查询参数",
                "results": []
            }), 400
        
        # 从环境变量中获取API密钥
        api_key = os.environ.get("DEEPSEEK_API_KEY")
        
        # 检查API密钥是否存在
        if not api_key:
            return jsonify({
                "success": False,
                "message": "DeepSeek API密钥未设置，无法执行向量搜索，请在.env文件中设置DEEPSEEK_API_KEY",
                "results": []
            }), 500
        
        # 初始化向量存储
        if DATABASE_TYPE == "mysql" and MYSQL_AVAILABLE:
            vector_store = VectorStore(
                database_type="mysql",
                mysql_config=MYSQL_CONFIG,
                api_key=api_key,
                embedding_model="deepseek-embed"  # 更新为DeepSeek的嵌入模型
            )
        else:
            # 使用SQLite作为备用
            vector_store = VectorStore(
                database_type="sqlite",
                api_key=api_key,
                embedding_model="deepseek-embed"  # 更新为DeepSeek的嵌入模型
            )
        
        # 执行搜索
        results = vector_store.search_similar_texts(
            query_text=query,
            top_k=top_k,
            filters=filters
        )
        
        # 检查结果是否为空
        if not results:
            return jsonify({
                "success": True,
                "message": "未找到相关内容，可能是因为向量搜索未正确配置或文档未被正确向量化",
                "query": query,
                "results": []
            })
        
        return jsonify({
            "success": True,
            "message": f"找到{len(results)}个相关结果",
            "query": query,
            "results": results
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "message": f"搜索失败: {str(e)}",
            "results": []
        }), 500

# 添加提供HTML文件的路由
@app.route('/<html_file>.html')
def serve_html(html_file):
    """提供HTML文件"""
    # 先尝试从static文件夹提供
    if os.path.exists(os.path.join('static', f"{html_file}.html")):
        return send_from_directory('static', f"{html_file}.html")
    # 如果static中没有，尝试从项目根目录提供
    elif os.path.exists(f"{html_file}.html"):
        return send_from_directory('.', f"{html_file}.html")
    else:
        return f"找不到文件: {html_file}.html", 404

# 添加提供easy_upload.html的路由
@app.route('/easy_upload')
def easy_upload():
    """提供简化的上传向量化一体化界面"""
    return send_from_directory('static', 'easy_upload.html')

# 添加获取处理进度的API端点
@app.route('/admin/api/processing_status', methods=['GET'])
def get_processing_status():
    """
    获取文档处理的进度状态
    
    请求参数:
    - doc_id: 文档ID
    
    返回:
    - 处理状态的JSON
    """
    doc_id = request.args.get('doc_id')
    
    if not doc_id:
        return jsonify({
            "success": False,
            "message": "缺少文档ID参数"
        }), 400
    
    # 获取处理状态
    status = processing_status.get(doc_id, {
        "status": "unknown",
        "progress": 0,
        "message": "未找到该文档的处理状态"
    })
    
    return jsonify({
        "success": True,
        "doc_id": doc_id,
        "data": status
    })

if __name__ == '__main__':
    # 应用启动诊断信息
    print("--- Flask 应用启动诊断 ---")
    print(f"试图导入的函数信息: {imported_parse_function_info}")
    if parse_opml_function_to_use:
        print(f"将要使用的解析函数来源模块: {inspect.getmodule(parse_opml_function_to_use)}")
        print(f"将要使用的解析函数名称: {parse_opml_function_to_use.__name__}")
        print("注意：当前看起来是导入了名为 parse_opml_to_json_tree 的函数。")
    else:
        print("警告：未能成功导入 parse_opml_to_json_tree 函数。")
    print("--------------------------")
    app.logger.info("Flask Admin API 服务准备启动 (主程序块)...")
    
    # 测试数据库连接
    success, message, db_type = test_db_connection()
    if success:
        print(f"使用 {db_type.upper()} 数据库")
    else:
        print(f"警告: {message}")
    
    # 启动应用
    app.run(host='0.0.0.0', port=5003, debug=True)
